{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"Yc-pqikOsyOE"},"outputs":[],"source":["# Clone our repo (containing models implementations, dataloaders, tasks and experiment definitions and training code)\n","! git clone https://oauth2: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@github.com/matanbt/advanced-dl--assignment-1.git\n","%cd advanced-dl--assignment-1/"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DV4BCOohybyi"},"outputs":[],"source":["! pip install datasets\n","! pip install livelossplot\n","! pip install einops"]},{"cell_type":"code","source":["import torch\n","from numba import cuda\n","\n","print(\"gpu?\", torch.cuda.is_available())\n","# cuda.get_current_device().reset()\n","\n","import os\n","os.environ['CUDA_LAUNCH_BLOCKING'] = '1'"],"metadata":{"id":"45i15DCJ_766"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Choosing architectures for the task\n","\n","We fix the backbone's parameter count to 0.1M, by setting hidden dimension of 64 features and varying depth (=layer count)."],"metadata":{"id":"IPizDs83ALCU"}},{"cell_type":"code","source":["from generic_classifier import GenericClassifier\n","from utils import print_num_params\n","from models.lstm import LSTMEncoder\n","from models.transformer import TransformerEncoder\n","from models.s4 import S4Encoder\n","\n","lstm_cfg = {'hidden_dim': 64, 'num_layers': 3, 'encoder_module': LSTMEncoder}\n","print(lstm_cfg)\n","print_num_params(LSTMEncoder(**lstm_cfg))\n","\n","transformer_cfg = {'hidden_dim': 64, 'num_layers': 2, 'encoder_module': TransformerEncoder}\n","print(transformer_cfg)\n","print_num_params(TransformerEncoder(**transformer_cfg))\n","\n","\n","s4_cfg = {'hidden_dim': 64, 'num_layers': 6, 'encoder_module': S4Encoder}\n","print(s4_cfg)\n","print_num_params(S4Encoder(**s4_cfg))\n","\n","cuda.get_current_device().reset()"],"metadata":{"id":"QTc5dce9-o47"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Experiment 1: Training on ListOps (only)"],"metadata":{"id":"MZZwRXGk-vCV"}},{"cell_type":"code","source":["from experiments import setting_1__directly_on_listops\n","BATCH_SIZE = 1024  # TODO need to find the one maximizing VRAM usage\n","TRAIN_TIME_LIMIT = 500  # seconds to limit the train time, due to colab limit\n","NUM_EPOCHS = 10  # set amount of epoch (mostly time limit will come first)\n","exp1_model2metric = {}"],"metadata":{"id":"jK-PsNLDAgKa"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### LSTM"],"metadata":{"id":"MLneeSZlA7DD"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"Y9aP4SFDxleH"},"outputs":[],"source":["model, test_acc = setting_1__directly_on_listops(\n","    model_cls=GenericClassifier,\n","    model_kwargs=lstm_cfg,\n","    batch_size=BATCH_SIZE,\n","    num_epochs=NUM_EPOCHS,\n","    train_time_limit_secs=TRAIN_TIME_LIMIT\n",")\n","\n","exp1_model2metric['lstm'] = test_acc"]},{"cell_type":"markdown","source":["## Transformer"],"metadata":{"id":"d_8ZWpFCBUfE"}},{"cell_type":"code","source":["model, test_acc = setting_1__directly_on_listops(\n","    model_cls=GenericClassifier,\n","    model_kwargs=lstm_cfg,\n","    batch_size=BATCH_SIZE,\n","    num_epochs=NUM_EPOCHS,\n","    train_time_limit_secs=TRAIN_TIME_LIMIT\n",")\n","\n","exp1_model2metric['fransformer'] = test_acc\n","\n","# cuda.get_current_device().reset()"],"metadata":{"id":"G2UV1a5lBUml"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## S4"],"metadata":{"id":"LpCCSSraBU5c"}},{"cell_type":"code","source":["model, test_acc = setting_1__directly_on_listops(\n","    model_cls=GenericClassifier,\n","    model_kwargs=s4_cfg,\n","    batch_size=BATCH_SIZE,\n","    num_epochs=NUM_EPOCHS,\n","    train_time_limit_secs=TRAIN_TIME_LIMIT\n",")\n","\n","exp1_model2metric['s4'] = test_acc\n","\n","# cuda.get_current_device().reset()"],"metadata":{"id":"yEhbjRuNBVA9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Experiment 2: PreTrain (CLM) on wikitext -> fintune on ListOps"],"metadata":{"id":"gKtoIYXYDBLF"}},{"cell_type":"code","source":["from experiments import setting_2__clm_pretrain_text_then_listops\n","BATCH_SIZE = 1024  # TODO need to find the one maximizing VRAM usage\n","TRAIN_TIME_LIMIT = 500  # seconds to limit the train time, due to colab limit\n","NUM_EPOCHS = 10  # set amount of epoch (mostly time limit will come first)\n","exp1_model2metric = {}"],"metadata":{"id":"-iHGhZtKDBLG"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### LSTM"],"metadata":{"id":"qNCwSA_jDBLG"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"Spmv8gDfDBLG"},"outputs":[],"source":["model, test_acc = setting_2__clm_pretrain_text_then_listops(\n","    model_cls=GenericClassifier,\n","    model_kwargs=lstm_cfg,\n","    batch_size=BATCH_SIZE,\n","    num_epochs=NUM_EPOCHS,\n","    train_time_limit_secs=TRAIN_TIME_LIMIT\n",")\n","\n","exp1_model2metric['lstm'] = test_acc"]},{"cell_type":"markdown","source":["## Transformer"],"metadata":{"id":"txHycFKWDBLH"}},{"cell_type":"code","source":["model, test_acc = setting_2__clm_pretrain_text_then_listops(\n","    model_cls=GenericClassifier,\n","    model_kwargs=lstm_cfg,\n","    batch_size=BATCH_SIZE,\n","    num_epochs=NUM_EPOCHS,\n","    train_time_limit_secs=TRAIN_TIME_LIMIT\n",")\n","\n","exp1_model2metric['transformer'] = test_acc\n","\n","# cuda.get_current_device().reset()"],"metadata":{"id":"TXSyfS8HDBLI"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## S4"],"metadata":{"id":"V4SC_b3FDBLI"}},{"cell_type":"code","source":["model, test_acc = setting_2__clm_pretrain_text_then_listops(\n","    model_cls=GenericClassifier,\n","    model_kwargs=s4_cfg,\n","    batch_size=BATCH_SIZE,\n","    num_epochs=NUM_EPOCHS,\n","    train_time_limit_secs=TRAIN_TIME_LIMIT\n",")\n","\n","exp1_model2metric['s4'] = test_acc\n","\n","# cuda.get_current_device().reset()"],"metadata":{"id":"UGk43zRsDBLJ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Experiment 3: PreTrain (CLM) on ListOps -> fintune on ListOps"],"metadata":{"id":"yUuYrMyRDHGb"}},{"cell_type":"code","source":["from experiments import setting_3__clm_pretrain_listops_then_listops\n","BATCH_SIZE = 1024  # TODO need to find the one maximizing VRAM usage\n","TRAIN_TIME_LIMIT = 500  # seconds to limit the train time, due to colab limit\n","NUM_EPOCHS = 10  # set amount of epoch (mostly time limit will come first)\n","exp1_model2metric = {}"],"metadata":{"id":"C47IwTQkDHGc"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### LSTM"],"metadata":{"id":"oA5u_wQ0DHGc"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"Gj14IfNGDHGc"},"outputs":[],"source":["model, test_acc = setting_3__clm_pretrain_listops_then_listops(\n","    model_cls=GenericClassifier,\n","    model_kwargs=lstm_cfg,\n","    batch_size=BATCH_SIZE,\n","    num_epochs=NUM_EPOCHS,\n","    train_time_limit_secs=TRAIN_TIME_LIMIT\n",")\n","\n","exp1_model2metric['lstm'] = test_acc"]},{"cell_type":"markdown","source":["## Transformer"],"metadata":{"id":"2eXddqVzDHGc"}},{"cell_type":"code","source":["model, test_acc = setting_3__clm_pretrain_listops_then_listops(\n","    model_cls=GenericClassifier,\n","    model_kwargs=lstm_cfg,\n","    batch_size=BATCH_SIZE,\n","    num_epochs=NUM_EPOCHS,\n","    train_time_limit_secs=TRAIN_TIME_LIMIT\n",")\n","\n","exp1_model2metric['transformer'] = test_acc\n","\n","# cuda.get_current_device().reset()"],"metadata":{"id":"6TlEJbTaDHGd"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## S4"],"metadata":{"id":"2WXrHu7NDHGd"}},{"cell_type":"code","source":["model, test_acc = setting_3__clm_pretrain_listops_then_listops(\n","    model_cls=GenericClassifier,\n","    model_kwargs=s4_cfg,\n","    batch_size=BATCH_SIZE,\n","    num_epochs=NUM_EPOCHS,\n","    train_time_limit_secs=TRAIN_TIME_LIMIT\n",")\n","\n","exp1_model2metric['s4'] = test_acc\n","\n","# cuda.get_current_device().reset()"],"metadata":{"id":"BC7Rsrv7DHGz"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[{"file_id":"12K3ASzasSF9K8FMysoV4fLr9sPgeJk3A","timestamp":1720253442927}],"collapsed_sections":["IPizDs83ALCU","MZZwRXGk-vCV","gKtoIYXYDBLF","yUuYrMyRDHGb","2eXddqVzDHGc","2WXrHu7NDHGd"],"gpuType":"T4","authorship_tag":"ABX9TyMbMX4DEhrSJpRxreCaO1jD"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}